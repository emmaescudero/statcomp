<<<<<<< HEAD
b[-1,]   # The price is increasing by 8% in the case of cutGood as the value given is 1.083.
=======
b[-1,]
>>>>>>> 2bd5068f5bca1f49ebc44833bcf676d953e4949c
mygrid= data_grid(diamonds2, cut, color, clarity, .model=lmfit2)
mygrid
lmpred2= add_predictions(mygrid, model=lmfit2)
lmpred2
ggplot(lmpred2, aes(x=clarity, y=pred, color=color)) +
geom_point() +
facet_wrap(~ cut) +
labs(y='log2 (price)')
coefSummary(lmfit2)
C= matrix(0,nrow=1, ncol=length(coef(lmfit2)))
C[1,5]= -1; C[1,6]=1
C[1,1:10] #show first 10 columns
PvsI= glht(lmfit2, C)
summary(PvsI)
confint(PvsI)
bhat= matrix(coef(lmfit2), ncol=1)
V= vcov(lmfit2)
sqrt(diag(V)) #SE's for beta's (compare to summary(lmfit2))
dhat= C %*% bhat
se= sqrt(C %*% V %*% t(C))
se
dhat.ci= c(dhat, dhat - 1.96 * se, dhat + 1.96 * se)
round(dhat.ci, 4)
#| code-fold: true
<<<<<<< HEAD
ggplot(diamonds2, aes(lcarat, lprice, color=cut)) +  #the effect of one variable may depend of the value of another variable
geom_point() +
geom_smooth(method='lm', se=FALSE)
lmfit3= lm(lprice ~ lcarat + cut + lcarat:cut, data=diamonds2)
coefSummary(lmfit3)  #0,241 is the difference between the slope. This number tells us the large that is the slope related to the other lcarat cateories.
=======
ggplot(diamonds2, aes(lcarat, lprice, color=cut)) +
geom_point() +
geom_smooth(method='lm', se=FALSE)
lmfit3= lm(lprice ~ lcarat + cut + lcarat:cut, data=diamonds2)
coefSummary(lmfit3)
>>>>>>> 2bd5068f5bca1f49ebc44833bcf676d953e4949c
lmfit4= lm(lprice ~ lcarat + cut, data=diamonds2)
anova(lmfit4, lmfit3)
lmfull= lm(lprice ~ lcarat + cut + color + clarity + lcarat:cut + lcarat:color + lcarat:clarity, data=diamonds2)
lmdrop1= lm(lprice ~ lcarat + cut + color + clarity + lcarat:color + lcarat:clarity, data=diamonds2)
pvalue1= anova(lmdrop1, lmfull)[['Pr(>F)']][2]
lmdrop2= lm(lprice ~ lcarat + cut + color + clarity + lcarat:cut + lcarat:clarity, data=diamonds2)
pvalue2= anova(lmdrop2, lmfull)[['Pr(>F)']][2]
lmdrop3= lm(lprice ~ lcarat + cut + color + clarity + lcarat:cut + lcarat:color, data=diamonds2)
pvalue3= anova(lmdrop3, lmfull)[['Pr(>F)']][2]
c(pvalue1, pvalue2, pvalue3)
summary(lmfit2)$r.squared
summary(lmfull)$r.squared
diamonds2$predfull= predict(lmfull)
cor(diamonds2$pred2, diamonds2$predfull)
s= coefSummary(lmfit3)
sel= grep("lcarat:",s$Parameter)
knitr::kable(s[sel,])
s= coefSummary(lmfull)
sel= grep("lcarat:",s$Parameter)
knitr::kable(s[sel,])
multiplot(lmfull, lmfit3, intercept=FALSE)
<<<<<<< HEAD
x1= rnorm(100); x2= rnorm(100); x3= rnorm(100)
y= rnorm(100, x1 + x2/2, sd=1)  #y = x1 + x2/2 + e, e ~ N(0,1)
fit1= lm(y ~ x1 + x2 + x3 + x1:x2 + x1:x3 + x2:x3)
fit2= lm(y ~ x1*x2 + x1*x3 + x2*x3) #with * you can drop the additive terms
fit3= lm(y ~ (x1 + x2 + x3)^2) #^2 adds main effects + interactions in one go
fit3
library(gapminder)
gapminder
ggplot(gapminder, aes(year, lifeExp, group = country)) +
geom_line() + facet_wrap(~ continent)  #In most countries there has been an increase. We must consider adding a regression line between the country and the time (year).
=======
library(gapminder)
gapminder
ggplot(gapminder, aes(year, lifeExp, group = country)) +
geom_line() + facet_wrap(~ continent)
>>>>>>> 2bd5068f5bca1f49ebc44833bcf676d953e4949c
gm_country= group_by(gapminder, country, continent) %>% nest()
gm_country
fitmodel= function(df) {
fit= lm(lifeExp ~ year, data=df)
ans= c(coef(fit), summary(fit)$r.squared)
names(ans)= c('b0','b1','R2')
return(ans)
}
coef_gm = map_df(gm_country$data, fitmodel)
coef_gm = cbind(gm_country, coef_gm)
coef_gm
<<<<<<< HEAD
coef_gmu= unnest(coef_gm, cols=names(coef_gm))  #unnest & keep all columns
coef_gmu$pred= coef_gmu$b0 + coef_gmu$b1 * coef_gmu$year
coef_gmu
```
#dplyr:filter and dplyr::select ensures using functions (filter,select) from package dplyr
dplyr::filter(coef_gm, R2 < 0.5) |> dplyr::select(country, continent, R2)
coef_gmu= unnest(coef_gm, cols=names(coef_gm))  #unnest & keep all columns
coef_gmu$pred= coef_gmu$b0 + coef_gmu$b1 * coef_gmu$year
coef_gmu
```
coef_gmu= unnest(coef_gm, cols=names(coef_gm))  #unnest & keep all columns
coef_gmu$pred= coef_gmu$b0 + coef_gmu$b1 * coef_gmu$year
coef_gmu
```
coef_gmu= unnest(coef_gm, cols=names(coef_gm))  #unnest & keep all columns
coef_gmu$pred= coef_gmu$b0 + coef_gmu$b1 * coef_gmu$year
coef_gmu
```
coef_gmu= unnest(coef_gm, cols=names(coef_gm))  #unnest & keep all columns
coef_gmu$pred= coef_gmu$b0 + coef_gmu$b1 * coef_gmu$year
coef_gmu
poorfit= filter(coef_gmu, R2 < 0.25)
ggplot(poorfit) +
geom_line(aes(year, lifeExp)) +
geom_line(aes(year, pred), col='red') +
facet_wrap(~ country)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
options(repos = list(CRAN="http://cran.rstudio.com/"))
library(coefplot)
library(ggpubr)
library(gapminder)
library(hexbin)
library(modelr)
library(multcomp)
library(tidyverse)
source("/Users/emmaescudero/Documents/GitHub/statcomp/code/routines.R") #recall to set path to directory
source("/Users/emmaescudero/Documents/modern/code/routines.R")
gm3 = gapminder |>
filter(country %in% c("France", "Italy", "Spain")) |>
transform(country = factor(country), years_since_1952 = year - 1952)
fit1 <- lm(lifeExp ~ years_since_1952 + country, data=gm3)
coefSummary(fit1)
gm3 = gapminder |>
filter(country %in% c("France", "Italy", "Spain")) |>
transform(country = factor(country), years_since_1952 = year - 1952)
fit1 <- lm(lifeExp ~ years_since_1952 + country, data=gm3)
coefSummary(fit1)
levels(gm3$country)
contrasts(gm3$country)
contr.sum(levels(gm3$country))
gm3$country0= gm3$country #create new variable
c0= contr.sum(levels(gm3$country0)) #tell contr.sum the factor levels
colnames(c0)= c('France','Italy')   #set column names to facilitate interpreting coef.
contrasts(gm3$country0) = c0
fit2= lm(lifeExp ~ years_since_1952 + country0, data=gm3)
coefSummary(fit2)
contrasts(gm3$country)
contr.sum(levels(gm3$country))   #check what the sum-to-zero codes look like
install.packages("coin")
install.packages("lmPerm")
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
options(repos = list(CRAN="http://cran.rstudio.com/"))
library(tidyverse)
library(boot)
library(coin)
library(fivethirtyeight)
library(lmPerm)
library(ggpubr)
library(plyr)
source("/Users/emmaescudero/Documents/modern/code/routines.R")
baseball= baseball[baseball$year >= 1990, ]
head(baseball)
bat.avg= function(data, indices=1:nrow(data)) {
sum(data[indices, "h"], na.rm=TRUE) /
sum(data[indices, "ab"], na.rm=TRUE)
}
bat.avg(baseball)
set.seed(12345)
B= 2000; n= nrow(baseball)
th= double(B)
for (b in 1:B) {
idx= sample(1:n, size=n, replace=TRUE)
th[b]= bat.avg(baseball, indices=idx)
}
quantile(th, probs=c(.025,0.975)) #Boostrap-based 95% CI
th= tibble(th)
ggplot(th, aes(x=th)) + geom_histogram(aes(y= ..density..)) + stat_overlay_normal_density(linetype='dashed')
ggplot(th, aes(sample=th)) + geom_qq() + geom_qq_line(col='red')
avgBoot= boot(data=baseball, statistic=bat.avg, R=2000)
summary(avgBoot)
quantile(avgBoot$t, probs=c(0.025,0.975))
data(mtcars)
dim(mtcars)
f= formula(mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am)
fit= lm(f, data=mtcars)
coefSummary(fit)
mtcars.pred= tibble(mpg=mtcars$mpg, mpg_pred= predict(fit))
mtcars.pred$res= mtcars.pred$mpg - mtcars.pred$mpg_pred
ggplot(mtcars.pred, aes(x=mpg_pred, y=res)) +
geom_point() +
geom_smooth()
ggplot(mtcars.pred, aes(sample=res)) +
geom_qq() +
geom_qq_line() +
labs(x='Sample quantile',y='Normal quantile')
bhat= function(data, indices=1:nrow(data), formula) {
fit= lm(formula, data=data[indices,])
return(coef(fit))
}
round(bhat(mtcars, formula=f), 3)
bhat.fit= boot(mtcars, statistic=bhat, R=2000, formula=f)
dim(bhat.fit$t)
round(bhat.fit$t,3)[1:5,] #show first five bootstrap samples
round(bhat.fit$t0, 3)
colnames(bhat.fit$t)= names(bhat.fit$t0)
bhat.boot= as_tibble(bhat.fit$t)
bhat.boot
bhat.bootlong= pivot_longer(bhat.boot, cols= names(bhat.boot), names_to="variable", values_to="bootstrap_value")
bhat.bootlong
ggplot(bhat.bootlong, aes(x=bootstrap_value)) +
geom_histogram(aes(y= ..density..)) +
stat_overlay_normal_density(linetype='dashed') +
facet_wrap(~ variable, scales="free")
#map_df gets quantiles for all columns, returns a data frame (tibble)
bhat.ci= map_df(bhat.boot, quantile, probs=c(0.025,0.975), na.rm=TRUE)
bhat.ci= cbind(varname= names(bhat.boot), bhat.ci)
coefSummary(fit)
#| code-fold: true
yvals= 1:length(coef(fit))
ci= cbind(bhat.ci, confint(fit), y.ols=yvals, y.boot=yvals+.1)
names(ci)= c('varname','low.boot','high.boot','low.ols','high.ols','y.ols','y.boot')
ggplot(ci) +
geom_segment(aes(x=low.ols,xend=high.ols,y=y.ols,yend=y.ols)) +
geom_segment(aes(x=low.boot,xend=high.boot,y=y.boot,yend=y.boot), color='red') +
geom_text(aes(x=low.ols, y=y.ols, label=varname), nudge_y = 0.3) +
labs(x='Confidence interval', y='') +
theme(axis.text.y=element_blank(),  axis.ticks.y=element_blank()) #remove y axis labels
data("rotarod", package = "coin")
rotarod
ggplot(rotarod, aes(group, time)) + geom_point()
tstat= function(data) {
xbar= aggregate(time ~ group, data=data, FUN=mean)
ans= sum((xbar$time - mean(xbar$time))^2)
return(ans)
}
tobs= tstat(rotarod)
tobs
B= 2000; n= nrow(rotarod)
t0= double(B)
for (b in 1:B) {
groupperm= rotarod$group[sample(1:n, size=n, replace=FALSE)]
dataperm= data.frame(time=rotarod$time, group=groupperm)
t0[b]= tstat(dataperm)
}
pvalue= mean(t0 >= tobs) #proportion of t0's >= tobs
pvalue
hist(t0,main='',xlab='Test statistic'); abline(v= tobs, col='blue')
#based on asymptotic theory
independence_test(time ~ group, data=rotarod, teststat="quadratic", distribution="asymptotic")
#permutation-based
independence_test(time ~ group, data=rotarod, teststat="quadratic", distribution="approximate")
states= as.data.frame(state.x77)
sel= c('Population','Illiteracy','Income','Frost')
states[,sel]= scale(states[,sel])  #standardize to zero mean, unit variance
fit1= lm(Murder~Population + Illiteracy+Income+Frost, data=states)
coefSummary(fit1)
fit2= lmp(Murder~Population + Illiteracy+Income+Frost, data=states)
summary(fit2)
#Residual permutation test for a single variable in linear regression
#Input
# - y: outcome
# - x1: covariate of interest
# - x2: other covariates
# - B: number of residual permutations to consider
# Output: estimated coefficients for x1 in the B permutations
lmResPerm.onevar= function(y, x1, x2, B=5000) {
if (!is.matrix(x2)) x2= as.matrix(x2)
fit= lm(x1 ~ x2)
x1hat= predict(fit)
e= residuals(fit)
bperm= double(B)
for (b in 1:B) {
eperm= e[sample(1:length(e), size=length(e), replace=FALSE)]
x1tilde= x1hat + eperm
fitperm= lm(y ~ x1tilde + x2)
bperm[b]= coef(fitperm)['x1tilde']
}
return(bperm)
}
y= states$Murder; x1= states$Population; x2= states[,c('Illiteracy','Income','Frost')]
bperm= lmResPerm.onevar(y, x1, x2, B=5000)
bobs= coef(fit1)['Population']
pvalue= mean(abs(bperm) > abs(bobs))
pvalue
x= cbind(Population=x1, x2)
fit1.resperm= lmResPerm(y, x, B=5000)
fit1.resperm$pvalue
summary(fit2)$coef
library(tidyverse)
library(boot)
library(fivethirtyeight)
library(lmPerm)
source("~/github/statcomp/code/routines.R")
library(tidyverse)
library(boot)
library(fivethirtyeight)
library(lmPerm)
source("/Users/emmaescudero/Documents/modern/code/routines.R")
=======
ggplot(coef_gm, aes(x=R2)) + geom_histogram()
filter(coef_gm, R2 < 0.5) %>% dplyr::select(country, continent, R2)
```
source("/Users/emmaescudero/Documents/GitHub/statcomp/code/routines.R") #recall to set path to directory
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
options(repos = list(CRAN="http://cran.rstudio.com/"))
library(fivethirtyeight)
>>>>>>> 2bd5068f5bca1f49ebc44833bcf676d953e4949c
sel= c('state_abbrev','avg_hatecrimes_per_100k_fbi','share_vote_trump','gini_index','share_pop_hs')
hc= hate_crimes[,sel]
names(hc)= c('state','hatecrimes_fbi','votes_trump','gini','hs')
hc= filter(hc, !is.na(hatecrimes_fbi)) #outcome must be non-missing
<<<<<<< HEAD
fit= lm(hatecrimes_fbi ~ votes_trump + gini + hs, data=hc)
set.seed(12345) #setting random seed generator
B= 2000; n= nrow(baseball) #we ask for 2000 subsamples
th= double(B) #the output
for (b in 1:B) {
idx= sample(1:n, size=n, replace=TRUE) #use the sample instruction to take entries from this vector (1:n) with all of the numbers, n of them and we do a replacement. So idx will be the indexes of the samples.
th[b]= bat.avg(baseball, indices=idx) #we call again the function. The first argument is the same but now we resample the indexes.
}
th[b]
th= tibble(th)
ggplot(th, aes(x=th)) + geom_histogram(aes(y= ..density..)) + stat_overlay_normal_density(linetype='dashed')
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
options(repos = list(CRAN="http://cran.rstudio.com/"))
source("/Users/emmaescudero/Documents/modern/code/routines.R")
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
options(repos = list(CRAN="http://cran.rstudio.com/"))
library(tidyverse)
library(boot)
library(fivethirtyeight)
library(lmPerm)
source("/Users/emmaescudero/Documents/modern/code/routines.R")
sel= c('state_abbrev','avg_hatecrimes_per_100k_fbi','share_vote_trump','gini_index','share_pop_hs')
hc= hate_crimes[,sel]
names(hc)= c('state','hatecrimes_fbi','votes_trump','gini','hs')
hc= filter(hc, !is.na(hatecrimes_fbi))
fit= lm(hatecrimes_fbi ~ votes_trump + gini + hs, data=hc)
View(hate_crimes)
b= function(hate_crimes, indices=1:nrow(hate_crimes), formula) {
fit= lm(formula, hate_crimes=hate_crimes[indices,])
return(coef(fit))
}
round(b(hate_crimes, formula=f), 3)
b= function(hate_crimes, indices=1:nrow(hate_crimes), formula) {
fit= lm(formula, hate_crimes=hate_crimes[indices,])
return(coef(fit))
}
round(b(hate_crimes, formula=fit), 3)
View(hc)
b= function(hc, indices=1:nrow(hate_crimes), fit) {
fit= lm(fit, hc=hc[indices,])
return(coef(fit))
}
round(b(hc, formula=fit), 3)
b
b= function(hc, indices=1:nrow(hc), fit) {
fit= lm(fit, data = hc[indices,])
return(coef(fit))
}
round(b(hc,fit), 3)
b= function(hc, indices=1:nrow(hc), formula) {
fit= lm(fit, data = hc[indices,])
return(coef(fit))
}
round(b(hc,formula = fit), 3)
fit= lm(hatecrimes_fbi ~ votes_trump + gini + hs, data=hc)
b= function(hc, indices=1:nrow(hc), formula=fit) {
fit= lm(fit, data = hc[indices,])
return(coef(fit))
}
round(b(hc,formula = fit), 3)
fit= lm(hatecrimes_fbi ~ votes_trump + gini + hs, data=hc)
f <- hatecrimes_fbi ~ votes_trump + gini + hs
fit= lm(hatecrimes_fbi ~ votes_trump + gini + hs, data=hc)
f <- formula(hatecrimes_fbi ~ votes_trump + gini + hs)
b= function(hc, indices=1:nrow(hc), formula=f) {
fit= lm(fit, data = hc[indices,])
return(coef(fit))
}
round(b(hc,formula = f), 3)
b
b.fit= boot(hc, statistic=b, R=2000, formula=f)
dim(b.fit$t)
round(b.fit$t,3)[1:5,]
round(b.fit$t0, 3)
fit= lm(hatecrimes_fbi ~ votes_trump + gini + hs, data=hc)
f = formula(hatecrimes_fbi ~ votes_trump + gini + hs)
b= function(hc, indices=1:nrow(hc), formula=f) {
fit= lm(fit, data = hc[indices,])
return(coef(fit))
}
round(b(hc,formula = f), 3)
b.fit= boot(hc, statistic=b, R=2000, formula=f)
dim(b.fit$t)
round(b.fit$t,3)[1:5,]
round(b.fit$t0, 3)
b.boot= as_tibble(b.fit$t)
b.ci= map_df(b.boot, quantile, probs=c(0.025,0.975), na.rm=TRUE)
b.ci= cbind(varname= names(b.boot), b.ci)
yvals= 1:length(coef(fit))
ci= cbind(b.ci, confint(fit), y.ols=yvals, y.boot=yvals+.1)
names(ci)= c('varname','low.boot','high.boot','low.ols','high.ols','y.ols','y.boot')
ggplot(ci) +
geom_segment(aes(x=low.ols,xend=high.ols,y=y.ols,yend=y.ols)) +
geom_segment(aes(x=low.boot,xend=high.boot,y=y.boot,yend=y.boot), color='blue') +
geom_text(aes(x=low.ols, y=y.ols, label=varname), nudge_y = 0.3) +
labs(x='Confidence interval', y='') +
theme(axis.text.y=element_blank(),  axis.ticks.y=element_blank())
yvals= 1:length(coef(fit))
ci= cbind(b.ci, confint(fit), y.ols=yvals, y.boot=yvals+.1)
names(ci)= c('varname','low.boot','high.boot','low.ols','high.ols','y.ols','y.boot')
ggplot(ci) +
geom_segment(aes(x=low.ols,xend=high.ols,y=y.ols,yend=y.ols)) +
geom_segment(aes(x=low.boot,xend=high.boot,y=y.boot,yend=y.boot), color='light blue') +
geom_text(aes(x=low.ols, y=y.ols, label=varname), nudge_y = 0.3) +
labs(x='Confidence interval', y='') +
theme(axis.text.y=element_blank(),  axis.ticks.y=element_blank())
yvals= 1:length(coef(fit))
ci= cbind(b.ci, confint(fit), y.ols=yvals, y.boot=yvals+.1)
names(ci)= c('varname','low.boot','high.boot','low.ols','high.ols','y.ols','y.boot')
ggplot(ci) +
geom_segment(aes(x=low.ols,xend=high.ols,y=y.ols,yend=y.ols)) +
geom_segment(aes(x=low.boot,xend=high.boot,y=y.boot,yend=y.boot), color='light pink') +
geom_text(aes(x=low.ols, y=y.ols, label=varname), nudge_y = 0.3) +
labs(x='Confidence interval', y='') +
theme(axis.text.y=element_blank(),  axis.ticks.y=element_blank())
yvals= 1:length(coef(fit))
ci= cbind(b.ci, confint(fit), y.ols=yvals, y.boot=yvals+.1)
names(ci)= c('varname','low.boot','high.boot','low.ols','high.ols','y.ols','y.boot')
ggplot(ci) +
geom_segment(aes(x=low.ols,xend=high.ols,y=y.ols,yend=y.ols)) +
geom_segment(aes(x=low.boot,xend=high.boot,y=y.boot,yend=y.boot), color='light pink') +
geom_text(aes(x=low.ols, y=y.ols, label=c("Intercept", "Votes Trump", "Gini", "Highschool")), nudge_y = 0.3) +
labs(x='Confidence interval', y='') +
theme(axis.text.y=element_blank(),  axis.ticks.y=element_blank())
yvals= 1:length(coef(fit))
ci= cbind(b.ci, confint(fit), y.ols=yvals, y.boot=yvals+.1)
names(ci)= c('varname','low.boot','high.boot','low.ols','high.ols','y.ols','y.boot')
ggplot(ci) +
geom_segment(aes(x=low.ols,xend=high.ols,y=y.ols,yend=y.ols)) +
geom_segment(aes(x=low.boot,xend=high.boot,y=y.boot,yend=y.boot), color='light pink') +
geom_text(aes(x=low.ols, y=y.ols, label=c("Intercept", "Votes Trump", "Gini", "Highschool")), nudge_y = 0.3) +
labs(x='Confidence interval', y="Distribution Bootstrap vs lm") +
theme(axis.text.y=element_blank(),  axis.ticks.y=element_blank())
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
options(repos = list(CRAN="http://cran.rstudio.com/"))
ag <- aggregate(dep_delay ~ year + month + day, data=flights, FUN=mean, na.rm=TRUE)
install.packages("skimr")
=======
View(hc)
lmfit <- lm(hatecrimes_fbi ~ votes_trump + gini + hs, data = hc)
lmfit
confint(lmfit, level = 0.95)
coefSummary(lmfit)
coefSummary(lmfit)
library(fivethirtyeight)
library(coefplot)
sel= c('state_abbrev','avg_hatecrimes_per_100k_fbi','share_vote_trump','gini_index','share_pop_hs')
hc= hate_crimes[,sel]
names(hc)= c('state','hatecrimes_fbi','votes_trump','gini','hs')
hc= filter(hc, !is.na(hatecrimes_fbi)) #outcome must be non-missing
coefSummary(lmfit)
res <- lmfit$assign
res
res <- lmfit$residuals
res
pred <- predict(lmfit)
ggplot(diamonds2, aes(pred, res)) +
geom_point() +
geom_smooth() +
geom_abline(slope=0, intercept=0, col='gray') +
labs(x='Model prediction', y='Residuals')
ggplot(hc, aes(pred, res)) +
geom_point() +
geom_smooth() +
geom_abline(slope=0, intercept=0, col='gray') +
labs(x='Model prediction', y='Residuals')
ggplot(hc, aes(x=pred, y=res)) +
geom_boxplot(mapping = aes(group = cut_width(pred2, 0.2))) +
labs(x='Model prediction', y='Residuals')
ggplot(hc, aes(x=pred, y=res)) +
geom_boxplot(mapping = aes(group = cut_width(pred, 0.2))) +
labs(x='Model prediction', y='Residuals')
library(ggpubr)
ggplot(hc, aes(x=res)) +
geom_histogram(aes(y= ..density..)) +
stat_overlay_normal_density(linetype = "dashed") +
labs(x='Residuals')
library(fivethirtyeight)
library(coefplot)
sel= c('state_abbrev','avg_hatecrimes_per_100k_fbi','share_vote_trump','gini_index','share_pop_hs')
hc= hate_crimes[,sel]
names(hc)= c('state','hatecrimes_fbi','votes_trump','gini','hs')
hc= filter(hc, !is.na(hatecrimes_fbi)) #outcome must be non-missing
library(fivethirtyeight)
library(coefplot)
sel= c('state_abbrev','avg_hatecrimes_per_100k_fbi','share_vote_trump','gini_index','share_pop_hs')
hc= hate_crimes[,sel]
names(hc)= c('state','hatecrimes_fbi','votes_trump','gini','hs')
hc= filter(hc, !is.na(hatecrimes_fbi)) #outcome must be non-missing
coefSummary(lmfit)
coefSummary(lmfit)
>>>>>>> 2bd5068f5bca1f49ebc44833bcf676d953e4949c
